{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BigXxV5Ho-Tc"
      },
      "outputs": [],
      "source": [
        "# gradient descent function\n",
        "import numpy as np\n",
        "def gradient_descent(X, y, learning_rate = 0.0001, max_iter = 1000, epsilon = 0.0001, print_output = True):\n",
        "\n",
        "  # number of obs\n",
        "  n = X.shape[0]\n",
        "\n",
        "  # initializing w\n",
        "  w = np.random.randn(X.shape[1],1)\n",
        "\n",
        "  # loop over max iterations\n",
        "  for i in range(max_iter):\n",
        "    yhat = X.dot(w)                        # prediction\n",
        "    loss = (y - yhat)**2                   # loss function\n",
        "    gradient = (1/n) * X.T.dot(yhat - y)   # gradient\n",
        "\n",
        "    cost = (2/n)*np.sum(loss)           # cost function\n",
        "\n",
        "    w = w - (learning_rate * gradient)\n",
        "\n",
        "    ## stop if convergence\n",
        "    if np.linalg.norm(learning_rate * gradient) < epsilon:\n",
        "      print(f'Convergence at iteration: {i}')\n",
        "      print('\\n')\n",
        "      break\n",
        "\n",
        "    if print_output:\n",
        "      print(f'\\n__________________________________________________________________ \\\n",
        "              \\nIteration # {i+1},\\nEstimate w = \\n{np.around(w, decimals=5)}, nCost: {cost: 0.5f}, \\nGradient: \\n{gradient}')\n",
        "  return w, gradient"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## illustration\n",
        "import numpy\n",
        "\n",
        "np.random.seed(630)\n",
        "x = np.random.rand(100)\n",
        "X = np.vstack([np.ones(len(x)), x]).T\n",
        "## let's create an oracle\n",
        "## THE TRUE y-intercept 2\n",
        "## THE TRUE slope 1.5\n",
        "## some random error\n",
        "y = 2 + 1.5*x + np.random.normal(0,0.4,100)\n",
        "y = y.reshape(-1,1)"
      ],
      "metadata": {
        "id": "i22iyNlnpfDB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X,y, learning_rate = 0.01,max_iter=10000, print_output=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfCa7pmdpnn9",
        "outputId": "975f8f04-7902-4e1b-d9de-be61dcee938f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergence at iteration: 2911\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.04517696],\n",
              "        [1.38397059]]),\n",
              " array([[ 0.00416752],\n",
              "        [-0.00908449]]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}