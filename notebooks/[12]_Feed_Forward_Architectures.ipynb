{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Review on Neural Networks**"
      ],
      "metadata": {
        "id": "qEUBq8Xklk9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neurons**\n",
        "\n",
        "* Most fundamental building block of a NN.\n",
        "* Performs two calculations : sum + activation\n",
        "* can mimic both nonlinear and linear models"
      ],
      "metadata": {
        "id": "qgNjs0XFlpw4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyJaZkpaljIh",
        "outputId": "f89e8e59-a52f-4ea5-9f11-0d2eb38d5945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of the sum function is 150900.0\n",
            "The result of the activation function is 150900.0\n"
          ]
        }
      ],
      "source": [
        "## y = price\n",
        "## x1: Area (sqft)\n",
        "## x2: Bedrooms\n",
        "## x3: Distance to city\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "## create a home example\n",
        "home1 = np.array([2000, 2, 10])\n",
        "\n",
        "## Neuron (weights are the unknowns, variables)\n",
        "## parameters\n",
        "## when you train a NN\n",
        "## these are randomly initialized, then using gradient descent optimized\n",
        "b = 120000  ## bias, y-intercept\n",
        "w = np.array([6.2, 12000, -550])\n",
        "\n",
        "## Neuron\n",
        "## 1) sum\n",
        "z = np.dot(w, home1) + b ##  tensorflow - faster computation, derivatives are calculated and saved\n",
        "print(f'The result of the sum function is {z}')\n",
        "\n",
        "## 2) activation\n",
        "#### do you want a regression activation? y = price\n",
        "\n",
        "def linear(z):\n",
        "  return z\n",
        "\n",
        "def relu(z):\n",
        "  return np.max((0,z))\n",
        "\n",
        "print(f'The result of the activation function is {relu(z)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## what do we need in the activation function?\n",
        "## linear is fast\n",
        "## max, min is computationally fast\n",
        "## abs values work well\n",
        "## might need to avoid exponential ()\n",
        "## taking the derivative is also easy"
      ],
      "metadata": {
        "id": "JciM_I_bnu4k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## for classification\n",
        "def logistic(z):\n",
        "  return 1 / (1+np.exp(z))\n",
        "\n",
        "## tanh\n",
        "## softmax - multi-label"
      ],
      "metadata": {
        "id": "O5giu9_rpFkV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## the first activation\n",
        "## the threshold logical unit\n",
        "## heaviside\n",
        "## classification (binary)\n",
        "\n",
        "def heaviside(z):\n",
        "  return 0 if z < 0 else 1"
      ],
      "metadata": {
        "id": "5zpL0XHSpgT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feed-Forward Architecture**\n",
        "\n",
        "This is the most common architercture. It is also called multi-layer perceptron. Even RNN, CNN contain a feed-forward part."
      ],
      "metadata": {
        "id": "KIK_TB5Ltfnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## sklearn there is little way to change the architecture parts\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "## instance\n",
        "nn = MLPClassifier()\n",
        "\n",
        "## do not need to specify the input layer\n",
        "## do not need to specify the output layer (activation output logistic, softmax)\n",
        "## hidden_layer_sizes = (10,)\n",
        "## 1 hidden layer with 10 neurons\n",
        "nn = MLPClassifier(hidden_layer_sizes=(10,))\n",
        "\n",
        "## you can also change your activation functions ONLY on the hidden layers\n",
        "## all hidden layers have the same activation functions\n",
        "nn = MLPClassifier(hidden_layer_sizes=(10,), activation =\"tanh\")\n",
        "\n",
        "## by default we have stochastic gradient descent optimizer ADAM\n",
        "nn = MLPClassifier(hidden_layer_sizes=(10,), activation =\"tanh\", solver = \"sgd\")\n",
        "\n",
        "## learning rate (step size - small step size takes longer but can perform better)\n",
        "nn = MLPClassifier(hidden_layer_sizes=(10,), activation =\"tanh\", solver = \"sgd\", learning_rate_init = 0.01)"
      ],
      "metadata": {
        "id": "fzaSrEditzJW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## we can't change activations within layers\n",
        "## hidden 1: activation = \"relu\", regularize using L2 norm, weights to be initialized at 0\n",
        "## hidden 2: activation = 'tanh\", dropping randomly (dropout), weights to be initialized with normal dist\n",
        "\n",
        "## tensorflow - keras - if you have GPUs , computations are divided by GPU core\n",
        "## pytorch"
      ],
      "metadata": {
        "id": "5mOK-UTpuHD3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Basics of Keras\n",
        "## Feed-Forward NNs are applied into Sequential class\n",
        "## Sequential - flow forward\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential"
      ],
      "metadata": {
        "id": "1FNcJGFCxXjp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## In Sequential you need\n",
        "## the layers (one by one) add them in a list\n",
        "## Input: input layer\n",
        "## Dense: Fully connected\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "        Input(shape = (3,)),\n",
        "        Dense(60, activation = \"relu\"),\n",
        "        Dense(20, activation = \"tanh\"),\n",
        "        Dense(1, activation = \"linear\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "KnufWb0nx5OJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "6xWDbdp6y4By",
        "outputId": "233827a8-e7d7-4343-eaeb-e2a3cdaedb1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)                  │             \u001b[38;5;34m240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │           \u001b[38;5;34m1,220\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m21\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,220</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,481\u001b[0m (5.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,481</span> (5.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,481\u001b[0m (5.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,481</span> (5.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWY_k9ybzVhi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}